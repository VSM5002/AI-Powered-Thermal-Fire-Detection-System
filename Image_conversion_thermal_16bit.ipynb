{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4caa3-5d35-4c9c-b54b-b974c3e78aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"deepnewbie/flir-thermal-images-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files and folders in the dataset directory\n",
    "import os\n",
    "\n",
    "files = os.listdir(path)\n",
    "print(\"Files and folders in dataset root:\")\n",
    "for f in files:\n",
    "    print(f)\n",
    "\n",
    "# Print all folders and subfolders recursively\n",
    "print(\"\\nAll folders and subfolders:\")\n",
    "for root, dirs, files in os.walk(path):\n",
    "    print(f\"Folder: {root}\")\n",
    "    for d in dirs:\n",
    "        print(f\"  Subfolder: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set RGB and thermal image directories for train and val splits\n",
    "train_rgb_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"train\", \"RGB\")\n",
    "train_thermal_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"train\", \"thermal_16_bit\")\n",
    "val_rgb_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"val\", \"RGB\")\n",
    "val_thermal_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"val\", \"thermal_16_bit\")\n",
    "\n",
    "print(\"Train RGB directory:\", train_rgb_dir)\n",
    "print(\"Train Thermal directory:\", train_thermal_dir)\n",
    "print(\"Val RGB directory:\", val_rgb_dir)\n",
    "print(\"Val Thermal directory:\", val_thermal_dir)\n",
    "\n",
    "# Match images by filename prefix (without extension, ignoring extension differences)\n",
    "def get_matched_files_by_prefix(rgb_dir, thermal_dir, exclude_prefix=None):\n",
    "    rgb_files = [f for f in os.listdir(rgb_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    thermal_files = [f for f in os.listdir(thermal_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    rgb_prefix = {os.path.splitext(f)[0]: f for f in rgb_files}\n",
    "    thermal_prefix = {os.path.splitext(f)[0]: f for f in thermal_files}\n",
    "    common_prefixes = sorted(set(rgb_prefix.keys()) & set(thermal_prefix.keys()))\n",
    "    if exclude_prefix is not None:\n",
    "        common_prefixes = [p for p in common_prefixes if p != exclude_prefix]\n",
    "    matched_rgb = [rgb_prefix[p] for p in common_prefixes]\n",
    "    matched_thermal = [thermal_prefix[p] for p in common_prefixes]\n",
    "    return matched_rgb, matched_thermal, common_prefixes\n",
    "\n",
    "# Exclude FLIR_00001 from training\n",
    "matched_rgb, matched_thermal, matched_prefixes = get_matched_files_by_prefix(train_rgb_dir, train_thermal_dir, exclude_prefix=\"FLIR_00001\")\n",
    "val_matched_rgb, val_matched_thermal, val_matched_prefixes = get_matched_files_by_prefix(val_rgb_dir, val_thermal_dir)\n",
    "print(f\"Number of matched train RGB images: {len(matched_rgb)}\")\n",
    "print(f\"Number of matched train thermal images: {len(matched_thermal)}\")\n",
    "print(f\"Number of matched val RGB images: {len(val_matched_rgb)}\")\n",
    "print(f\"Number of matched val thermal images: {len(val_matched_thermal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca3c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset and U-Net model for RGB to thermal translation\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class FLIRRGB2ThermalDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, thermal_dir, img_size=256, matched_rgb=None, matched_thermal=None):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.thermal_dir = thermal_dir\n",
    "        self.img_size = img_size\n",
    "        # Use matched file lists if provided, else match by prefix\n",
    "        if matched_rgb is not None and matched_thermal is not None:\n",
    "            self.rgb_files = matched_rgb\n",
    "            self.thermal_files = matched_thermal\n",
    "        else:\n",
    "            rgb_files = [f for f in os.listdir(rgb_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            thermal_files = [f for f in os.listdir(thermal_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            rgb_prefix = {os.path.splitext(f)[0]: f for f in rgb_files}\n",
    "            thermal_prefix = {os.path.splitext(f)[0]: f for f in thermal_files}\n",
    "            common_prefixes = sorted(set(rgb_prefix.keys()) & set(thermal_prefix.keys()))\n",
    "            self.rgb_files = [rgb_prefix[p] for p in common_prefixes]\n",
    "            self.thermal_files = [thermal_prefix[p] for p in common_prefixes]\n",
    "        print(f\"Paired {len(self.rgb_files)} RGB and thermal images.\")\n",
    "        if len(self.rgb_files) == 0:\n",
    "            raise ValueError(\"No matching RGB and thermal image pairs found!\")\n",
    "        self.transform_rgb = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.transform_thermal = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rgb_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path = os.path.join(self.rgb_dir, self.rgb_files[idx])\n",
    "        thermal_path = os.path.join(self.thermal_dir, self.thermal_files[idx])\n",
    "        rgb = Image.open(rgb_path).convert('RGB')\n",
    "        thermal = Image.open(thermal_path).convert('L')\n",
    "        rgb = self.transform_rgb(rgb)\n",
    "        thermal = self.transform_thermal(thermal)\n",
    "        return rgb, thermal\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        for feature in features:\n",
    "            self.downs.append(self.conv_block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(self.conv_block(feature*2, feature))\n",
    "        self.bottleneck = self.conv_block(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = nn.MaxPool2d(2)(x)\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            if x.shape != skip.shape:\n",
    "                x = T.functional.resize(x, skip.shape[2:])\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.ups[idx+1](x)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98bbae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for the U-Net model with diagnostics and quick test mode\n",
    "def train_model(\n",
    "    rgb_dir, thermal_dir, matched_rgb, matched_thermal, epochs=10, batch_size=8, lr=5e-4, img_size=256, save_path='unet_rgb2thermal.pth', max_samples=100\n",
    "):\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataset = FLIRRGB2ThermalDataset(rgb_dir, thermal_dir, img_size, matched_rgb=matched_rgb, matched_thermal=matched_thermal)\n",
    "    if max_samples is not None:\n",
    "        indices = list(range(min(max_samples, len(dataset))))\n",
    "        from torch.utils.data import Subset\n",
    "        dataset = Subset(dataset, indices)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    model = UNet().to(device)\n",
    "    criterion = nn.L1Loss()  # Try nn.MSELoss() for even smoother results\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float('inf')\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        for i, (rgb, thermal) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "            rgb, thermal = rgb.to(device), thermal.to(device)\n",
    "            pred = model(rgb)\n",
    "            loss = criterion(pred, thermal)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * rgb.size(0)\n",
    "            if (i+1) % 2 == 0:\n",
    "                print(f\"  Batch {i+1}/{len(loader)} - Batch Loss: {loss.item():.4f}\")\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Time: {elapsed:.1f}s\")\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Training complete. Best model saved.\")\n",
    "    return train_losses\n",
    "\n",
    "# Example usage:\n",
    "#train_losses = train_model(train_rgb_dir, train_thermal_dir, matched_rgb, matched_thermal, epochs=10, batch_size=8, lr=5e-4, max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize matched RGB and thermal image pairs in batches of 100\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_matched_images(rgb_dir, thermal_dir, matched_rgb, matched_thermal, batch_size=100):\n",
    "    total = len(matched_rgb)\n",
    "    for start in range(0, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        print(f\"Showing images {start} to {end-1}\")\n",
    "        fig, axes = plt.subplots(end - start, 2, figsize=(6, (end - start) * 2))\n",
    "        if end - start == 1:\n",
    "            axes = [axes]\n",
    "        for i, idx in enumerate(range(start, end)):\n",
    "            rgb_img = Image.open(os.path.join(rgb_dir, matched_rgb[idx]))\n",
    "            thermal_img = Image.open(os.path.join(thermal_dir, matched_thermal[idx]))\n",
    "            axes[i][0].imshow(rgb_img)\n",
    "            axes[i][0].set_title(f\"RGB: {matched_rgb[idx]}\")\n",
    "            axes[i][0].axis('off')\n",
    "            axes[i][1].imshow(thermal_img, cmap='gray')\n",
    "            axes[i][1].set_title(f\"Thermal: {matched_thermal[idx]}\")\n",
    "            axes[i][1].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example: Show first 100 matched pairs\n",
    "#show_matched_images(train_rgb_dir, train_thermal_dir, matched_rgb, matched_thermal, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b771176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model from scratch\n",
    "train_losses0 = train_model(\n",
    "    train_rgb_dir, \n",
    "    train_thermal_dir, \n",
    "    matched_rgb, \n",
    "    matched_thermal, \n",
    "    epochs=10, \n",
    "    batch_size=8, \n",
    "    lr=5e-4, \n",
    "    max_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f297c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model from scratch\n",
    "train_losses = train_model(\n",
    "    train_rgb_dir, \n",
    "    train_thermal_dir, \n",
    "    matched_rgb, \n",
    "    matched_thermal, \n",
    "    epochs=10, \n",
    "    batch_size=8, \n",
    "    lr=5e-4, \n",
    "    max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbc921",
   "metadata": {},
   "source": [
    "## Validation, Metrics, and Visualization\n",
    "\n",
    "Let's evaluate the model on a validation set, compute metrics, and visualize predictions vs. ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Use validation set from val/RGB and val/thermal_8_bit folders directly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load('unet_rgb2thermal.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "val_rgb_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"val\", \"RGB\")\n",
    "val_thermal_dir = os.path.join(path, \"FLIR_ADAS_1_3\", \"val\", \"thermal_8_bit\")\n",
    "\n",
    "val_matched_rgb, val_matched_thermal, _ = get_matched_files_by_prefix(val_rgb_dir, val_thermal_dir)\n",
    "\n",
    "val_dataset = FLIRRGB2ThermalDataset(val_rgb_dir, val_thermal_dir, img_size=256, matched_rgb=val_matched_rgb, matched_thermal=val_matched_thermal)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "outputs = []\n",
    "gts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for rgb, thermal in val_loader:\n",
    "        rgb, thermal = rgb.to(device), thermal.to(device)\n",
    "        pred = model(rgb)\n",
    "        pred_np = pred.squeeze().cpu().numpy()\n",
    "        gt_np = thermal.squeeze().cpu().numpy()\n",
    "        outputs.append(pred_np)\n",
    "        gts.append(gt_np)\n",
    "        mae_list.append(mean_absolute_error(gt_np.flatten(), pred_np.flatten()))\n",
    "        mse_list.append(mean_squared_error(gt_np.flatten(), pred_np.flatten()))\n",
    "\n",
    "print(f\"Validation MAE: {sum(mae_list)/len(mae_list):.4f}\")\n",
    "print(f\"Validation MSE: {sum(mse_list)/len(mse_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b67bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Binarize outputs and ground truth for classification metrics\n",
    "threshold = 0.5\n",
    "all_preds = []\n",
    "all_gts = []\n",
    "\n",
    "for pred_np, gt_np in zip(outputs, gts):\n",
    "    pred_bin = (pred_np > threshold).astype(int).flatten()\n",
    "    gt_bin = (gt_np > threshold).astype(int).flatten()\n",
    "    all_preds.extend(pred_bin)\n",
    "    all_gts.extend(gt_bin)\n",
    "\n",
    "accuracy = accuracy_score(all_gts, all_preds)\n",
    "precision = precision_score(all_gts, all_preds, zero_division=0)\n",
    "recall = recall_score(all_gts, all_preds, zero_division=0)\n",
    "f1 = f1_score(all_gts, all_preds, zero_division=0)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ba8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few predictions vs. ground truth\n",
    "num_show = 3\n",
    "plt.figure(figsize=(10, num_show * 3))\n",
    "for i in range(num_show):\n",
    "    plt.subplot(num_show, 2, 2*i+1)\n",
    "    plt.imshow(gts[i], cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(num_show, 2, 2*i+2)\n",
    "    plt.imshow(outputs[i], cmap='gray')\n",
    "    plt.title('Predicted')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3603e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model (if not already done)\n",
    "torch.save(model.state_dict(), 'unet_rgb2thermal_final.pth')\n",
    "print(\"Final model saved as unet_rgb2thermal_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
