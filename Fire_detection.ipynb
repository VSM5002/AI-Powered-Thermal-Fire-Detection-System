{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4caa3-5d35-4c9c-b54b-b974c3e78aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/deepnewbie/flir-thermal-images-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4.16G/15.3G [13:58<33:51, 5.87MB/s]  "
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"deepnewbie/flir-thermal-images-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files and folders in the dataset directory\n",
    "import os\n",
    "\n",
    "files = os.listdir(path)\n",
    "print(\"Files and folders in dataset root:\")\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Set RGB and thermal image directories based on dataset structure\n",
    "rgb_dir = os.path.join(path, \"FLIR_ADAS_v2\", \"images_rgb_8_bit\")\n",
    "thermal_dir = os.path.join(path, \"FLIR_ADAS_v2\", \"images_thermal_8_bit\")\n",
    "\n",
    "print(\"RGB directory:\", rgb_dir)\n",
    "print(\"Thermal directory:\", thermal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries if not already installed\n",
    "!pip install torch torchvision pillow kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca3c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset and U-Net model for RGB to thermal translation\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class FLIRRGB2ThermalDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, thermal_dir, img_size=256):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.thermal_dir = thermal_dir\n",
    "        self.img_size = img_size\n",
    "        self.rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "        self.thermal_files = sorted([f for f in os.listdir(thermal_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "        self.transform_rgb = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.transform_thermal = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rgb_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path = os.path.join(self.rgb_dir, self.rgb_files[idx])\n",
    "        thermal_path = os.path.join(self.thermal_dir, self.thermal_files[idx])\n",
    "        rgb = Image.open(rgb_path).convert('RGB')\n",
    "        thermal = Image.open(thermal_path).convert('L')\n",
    "        rgb = self.transform_rgb(rgb)\n",
    "        thermal = self.transform_thermal(thermal)\n",
    "        return rgb, thermal\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        for feature in features:\n",
    "            self.downs.append(self.conv_block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(self.conv_block(feature*2, feature))\n",
    "        self.bottleneck = self.conv_block(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = nn.MaxPool2d(2)(x)\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            if x.shape != skip.shape:\n",
    "                x = T.functional.resize(x, skip.shape[2:])\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.ups[idx+1](x)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f297c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for the U-Net model\n",
    "def train_model(\n",
    "    rgb_dir, thermal_dir, epochs=10, batch_size=4, lr=1e-4, img_size=256, save_path='unet_rgb2thermal.pth'\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataset = FLIRRGB2ThermalDataset(rgb_dir, thermal_dir, img_size)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    model = UNet().to(device)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for rgb, thermal in loader:\n",
    "            rgb, thermal = rgb.to(device), thermal.to(device)\n",
    "            pred = model(rgb)\n",
    "            loss = criterion(pred, thermal)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * rgb.size(0)\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Training complete. Best model saved.\")\n",
    "\n",
    "# Example usage:\n",
    "# train_model(rgb_dir, thermal_dir, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304315bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: Generate synthetic thermal image from RGB input\n",
    "def infer(rgb_img_path, model_path, img_size=256):\n",
    "    import numpy as np\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNet().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    img = Image.open(rgb_img_path).convert('RGB')\n",
    "    inp = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(inp)\n",
    "        out_img = out.squeeze().cpu().numpy()\n",
    "        out_img = (out_img * 255).clip(0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(out_img)\n",
    "\n",
    "# Example usage:\n",
    "# result = infer('path/to/sample_rgb.jpg', 'unet_rgb2thermal.pth')\n",
    "# result.save('synthetic_thermal.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
